{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Tugas Individu BPNN\n",
        "\n",
        "Muhammad Farhan Haniftyaji - 2006468711\n",
        "\n",
        "link : https://colab.research.google.com/drive/1TtMS3xAOxNfyUIDqmER1nZuBHt_Ttirh?usp=sharing"
      ],
      "metadata": {
        "id": "RZR9IlnvOQ8Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Library dan Dataset"
      ],
      "metadata": {
        "id": "FDxJeUqXOjGI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "UnMWbrEYNXFK"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6tIoXJkOpdr",
        "outputId": "45a24c64-f8d3-47c1-a3fc-8a415cd125b0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read dataset\n",
        "data = pd.read_csv('/content/drive/My Drive/dataset/Iris.csv')"
      ],
      "metadata": {
        "id": "e578PAFdSvKK"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing"
      ],
      "metadata": {
        "id": "o0ZQDdrfS1Qk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Delete Id column\n",
        "data.drop(['Id'], axis=1)\n",
        "\n",
        "# Encode target kelas\n",
        "species_map = {\n",
        "    'Iris-setosa': 0,\n",
        "    'Iris-virginica': 1,\n",
        "    'Iris-versicolor': 2\n",
        "}"
      ],
      "metadata": {
        "id": "xIF13cO1TI8-"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['Species'] = data['Species'].map(species_map)\n",
        "\n",
        "X = data[['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm']].values\n",
        "Y = np.eye(3)[data['Species'].values]"
      ],
      "metadata": {
        "id": "BVBCoLByUe5A"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "rTnvQlS4GorL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize weights in the range of -0.5 to 0.5\n",
        "def initialize_weights(nodes):\n",
        "    num_layers = len(nodes)\n",
        "    weights = []\n",
        "\n",
        "    for i in range(1, num_layers):\n",
        "        num_inputs = nodes[i-1] + 1\n",
        "        num_outputs = nodes[i]\n",
        "        layer_weights = np.random.uniform(low=-0.5, high=0.5, size=(num_outputs, num_inputs))\n",
        "        weights.append(layer_weights)\n",
        "\n",
        "    return weights"
      ],
      "metadata": {
        "id": "n9sDjwEtUk3O"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fungsi ini menginisialisasi bobot neural network dengan nilai random dalam range -0,5 hingga 0,5. Untuk setiap layer, fungsi menghasilkan bobot acak menggunakan fungsi distribusi seragam NumPy, dengan mempertimbangkan jumlah input dan output, dan menambahkan bobot ini ke list."
      ],
      "metadata": {
        "id": "PVkurdLsU8Jn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data into training and testing sets (70:30)\n",
        "def split_data(X, y, train_percent=70):\n",
        "    arr_rand = np.random.rand(X.shape[0])\n",
        "    split = arr_rand < np.percentile(arr_rand, train_percent)\n",
        "    X_train, y_train = X[split], y[split]\n",
        "    X_test, y_test = X[~split], y[~split]\n",
        "    return X_train, y_train, X_test, y_test\n",
        "\n",
        "X_train, Y_train, X_test, Y_test = split_data(X, Y)"
      ],
      "metadata": {
        "id": "GjmlpOwKVRlz"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fungsi ini melakukan split antara train dan testing dengan banyak data yang dipakai untuk training sebesar 70%. splitting juga mengambil data secara random dari dataset untuk evaluasi pada model"
      ],
      "metadata": {
        "id": "ppDNqiDXy1Tb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Processing\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def sigmoid_derivative(x):\n",
        "    return np.multiply(x, 1 - x)"
      ],
      "metadata": {
        "id": "kblOLlXdWKYP"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fungsi sigmoid ($ \\sigma(x)$) adalah fungsi aktivasi. Sigmoid memetakan bilangan asli ke kisaran antara 0 dan 1. Secara matematis didefinisikan sebagai:\n",
        "\n",
        "$ \\sigma(x) = \\frac{1}{1 + e^{-x}} $\n",
        "\n",
        "dengan :\n",
        "- $e$ adalah nilai euler\n",
        "- $x$ adalah input\n",
        "\n",
        "Turunan dari sigmoid biasa digunakan pada backpropagation untuk update  weights dari neural networks selama training."
      ],
      "metadata": {
        "id": "h8qoLkF6zcxt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Forward propagation\n",
        "def forward_propagation(inputs, weights, num_layers):\n",
        "    activations = [inputs]\n",
        "    current_layer_input = inputs\n",
        "\n",
        "    for layer in range(num_layers):\n",
        "        layer_output = np.dot(current_layer_input, weights[layer].T)\n",
        "        activation = sigmoid(layer_output)\n",
        "        activations.append(activation)\n",
        "        current_layer_input = np.append(1, activation)\n",
        "\n",
        "    return activations"
      ],
      "metadata": {
        "id": "myN1ZE_1Hey3"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fungsi ini menghitung output setiap layer dalam neural network berdasarkan data input dan bobotnya, kemudian menerapkan fungsi aktivasi sigmoid ke setiap output  layer."
      ],
      "metadata": {
        "id": "HmpzM6kr2xyk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Backpropagation\n",
        "def backpropagation(y, activations, weights, layers, lr):\n",
        "    output_final = activations[-1]\n",
        "    error = np.matrix(y - output_final)\n",
        "\n",
        "    for j in range(layers, 0, -1):\n",
        "        curr_activation = activations[j]\n",
        "\n",
        "        if j > 1:\n",
        "            prev_activation = np.append(1, activations[j - 1])\n",
        "        else:\n",
        "            prev_activation = activations[0]\n",
        "\n",
        "        delta = np.multiply(error, sigmoid_derivative(curr_activation))\n",
        "        weights[j - 1] += lr * np.multiply(delta.T, prev_activation)\n",
        "\n",
        "        w = np.delete(weights[j - 1], [0], axis=1)\n",
        "        error = np.dot(delta, w)\n",
        "\n",
        "    return weights"
      ],
      "metadata": {
        "id": "nbJoFHRFHfFE"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fungsi ini mengimplementasikan backpropagation untuk memperbarui bobot di neural network. Inputnya berupa target output (y), activation list setiap layer, bobot jaringan, jumlah layer, dan learning rate (lr). Dimulai dari lapisan output dan bergerak mundur, backpropagation menghitung error di setiap layer dengan mengambil selisih antara output target dan output asli, kemudian menyesuaikan bobot menggunakan gradient descent dengan learning rate. Nilai delta, yang mewakili gradien, dihitung berdasarkan turunan fungsi sigmoid, dan error pada setiap layer back propagation untuk memperbarui bobot layer sebelumnya. Terakhir, fungsi mengembalikan bobot yang diperbarui.\n"
      ],
      "metadata": {
        "id": "PcVjvJkE5IgV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train function\n",
        "def train(X, Y, lr, weights):\n",
        "    num_layers = len(weights)\n",
        "\n",
        "    for i in range(len(X)):\n",
        "        x, y = X[i], Y[i]\n",
        "        x = np.matrix(np.append(1, x))\n",
        "\n",
        "        activations = forward_propagation(x, weights, num_layers)\n",
        "        weights = backpropagation(y, activations, weights, num_layers, lr)\n",
        "\n",
        "    return weights"
      ],
      "metadata": {
        "id": "j1I4-dfeHip8"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fungsi ini dilakukan untuk training neural network menggunakan gradient descent dengan input data (X), learning rate (lr), dan bobot awal layer. Fungsi ini melakukan forward propagation yang diikuti backpropagation untuk memperbarui nilai bobot berdasarkan aktivasi dan target output"
      ],
      "metadata": {
        "id": "Fqj67vxh6c63"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train neural network\n",
        "def train_neural_network(X_train, Y_train, X_val=None, Y_val=None, epochs=10, nodes=[], lr=0.15):\n",
        "    hidden_layers = len(nodes) - 1\n",
        "    weights = initialize_weights(nodes)\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        weights = train(X_train, Y_train, lr, weights)\n",
        "        if epoch % 10 == 0:\n",
        "            print(f\"Epoch {epoch}\")\n",
        "            print(f\"Training Accuracy: {accuracy(X_train, Y_train, weights)}\")\n",
        "            if X_val is not None and Y_val is not None:\n",
        "                print(f\"Validation Accuracy: {accuracy(X_val, Y_val, weights)} \\n\")\n",
        "\n",
        "    return weights"
      ],
      "metadata": {
        "id": "f-S-z4AxHlXX"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fungsi ini melakukan training berdasarkan epoch yang di set kemudian tiap 10 epoch akan memberikan progres akurasi pada training dan validation"
      ],
      "metadata": {
        "id": "liENPgLG97LL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict function\n",
        "def predict(input_item, weights):\n",
        "    num_layers = len(weights)\n",
        "    input_item = np.append(1, input_item)\n",
        "    activations = forward_propagation(input_item, weights, num_layers)\n",
        "    final_output = activations[-1]\n",
        "    max_index = np.argmax(final_output)\n",
        "    prediction = np.zeros(len(final_output))\n",
        "    prediction[max_index] = 1\n",
        "    return prediction"
      ],
      "metadata": {
        "id": "PvKnZYOLHniR"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fungsi ini melakukan prediksi menggunakan neural network model yang sudah ditrain dengan menerima input dan weight. Fungsi ini menghitung aktivasi tiap layer menggunakan forward propagation.Hasil akhir diambil dari aktivasi pada layer terakhir.\n",
        "\n",
        "Dalam kasus klasifikasi ini, fungsi akan mengidentifikasi nilai maksimum dalam vektor output yang mewakili kelas yang diprediksi. Fungsi kemudian membuat vektor prediksi di mana elemen yang sesuai dengan indeks nilai maksimum yang di set nilai 1, sementara elemen yang lain adalah 0. fungsi kemudian mengembalikan vektor prediksi."
      ],
      "metadata": {
        "id": "zCAzLGZ0-gAD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Accuracy function\n",
        "def accuracy(X, Y, weights):\n",
        "    correct = 0\n",
        "\n",
        "    for i in range(len(X)):\n",
        "        x, y = X[i], list(Y[i])\n",
        "        guess = predict(x, weights)\n",
        "\n",
        "        if np.array_equal(y, guess):\n",
        "            correct += 1\n",
        "\n",
        "    return correct / len(X)"
      ],
      "metadata": {
        "id": "YYbpEiuwHqWk"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fungsi ini mencatat jumlah prediksi yang tepat dalam variable correct. Kemudian melakukan iterasi terhadap data point lalu melakukan passing terhadap input dan weight. Langkah selanjutnya adalah melakukan pembandingan antara nilai prediksi dengan target yang sebenarnya. Fungsi kemudian mengembalikan nilai yang benar terhadap jumlah data yang ada pada dataset."
      ],
      "metadata": {
        "id": "m4ktAVuslws1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define features dan output\n",
        "f = len(X[0])\n",
        "o = len(Y[0])\n",
        "\n",
        "# experiment with learning rate\n",
        "learning_rates = [0.1, 0.25, 0.5]\n",
        "results = []"
      ],
      "metadata": {
        "id": "WQ9318bWHsjt"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save results in list\n",
        "results = []\n",
        "\n",
        "for lr in learning_rates:\n",
        "    layers = [f, 5, 10, o]\n",
        "    weights = train_neural_network(X_train, Y_train, X_test, Y_test, epochs=100, nodes=layers, lr=lr)\n",
        "    training_accuracy = accuracy(X_train, Y_train, weights)\n",
        "    testing_accuracy = accuracy(X_test, Y_test, weights)\n",
        "    results.append([lr, training_accuracy, testing_accuracy])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BOlJWRXxHu05",
        "outputId": "a20ccef0-29d0-471e-fa26-f438a1bd3e42"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10\n",
            "Training Accuracy: 0.29523809523809524\n",
            "Validation Accuracy: 0.4222222222222222 \n",
            "\n",
            "Epoch 20\n",
            "Training Accuracy: 0.638095238095238\n",
            "Validation Accuracy: 0.7333333333333333 \n",
            "\n",
            "Epoch 30\n",
            "Training Accuracy: 0.638095238095238\n",
            "Validation Accuracy: 0.7333333333333333 \n",
            "\n",
            "Epoch 40\n",
            "Training Accuracy: 0.638095238095238\n",
            "Validation Accuracy: 0.7333333333333333 \n",
            "\n",
            "Epoch 50\n",
            "Training Accuracy: 0.6476190476190476\n",
            "Validation Accuracy: 0.7555555555555555 \n",
            "\n",
            "Epoch 60\n",
            "Training Accuracy: 0.6761904761904762\n",
            "Validation Accuracy: 0.8 \n",
            "\n",
            "Epoch 70\n",
            "Training Accuracy: 0.780952380952381\n",
            "Validation Accuracy: 0.8444444444444444 \n",
            "\n",
            "Epoch 80\n",
            "Training Accuracy: 0.8285714285714286\n",
            "Validation Accuracy: 0.9111111111111111 \n",
            "\n",
            "Epoch 90\n",
            "Training Accuracy: 0.8476190476190476\n",
            "Validation Accuracy: 0.9333333333333333 \n",
            "\n",
            "Epoch 100\n",
            "Training Accuracy: 0.8476190476190476\n",
            "Validation Accuracy: 0.9333333333333333 \n",
            "\n",
            "Epoch 10\n",
            "Training Accuracy: 0.29523809523809524\n",
            "Validation Accuracy: 0.4222222222222222 \n",
            "\n",
            "Epoch 20\n",
            "Training Accuracy: 0.29523809523809524\n",
            "Validation Accuracy: 0.4222222222222222 \n",
            "\n",
            "Epoch 30\n",
            "Training Accuracy: 0.6571428571428571\n",
            "Validation Accuracy: 0.7555555555555555 \n",
            "\n",
            "Epoch 40\n",
            "Training Accuracy: 0.780952380952381\n",
            "Validation Accuracy: 0.8444444444444444 \n",
            "\n",
            "Epoch 50\n",
            "Training Accuracy: 0.8095238095238095\n",
            "Validation Accuracy: 0.8888888888888888 \n",
            "\n",
            "Epoch 60\n",
            "Training Accuracy: 0.7428571428571429\n",
            "Validation Accuracy: 0.8 \n",
            "\n",
            "Epoch 70\n",
            "Training Accuracy: 0.8285714285714286\n",
            "Validation Accuracy: 0.8888888888888888 \n",
            "\n",
            "Epoch 80\n",
            "Training Accuracy: 0.8\n",
            "Validation Accuracy: 0.8666666666666667 \n",
            "\n",
            "Epoch 90\n",
            "Training Accuracy: 0.9238095238095239\n",
            "Validation Accuracy: 0.9555555555555556 \n",
            "\n",
            "Epoch 100\n",
            "Training Accuracy: 0.6476190476190476\n",
            "Validation Accuracy: 0.7555555555555555 \n",
            "\n",
            "Epoch 10\n",
            "Training Accuracy: 0.29523809523809524\n",
            "Validation Accuracy: 0.4222222222222222 \n",
            "\n",
            "Epoch 20\n",
            "Training Accuracy: 0.29523809523809524\n",
            "Validation Accuracy: 0.4222222222222222 \n",
            "\n",
            "Epoch 30\n",
            "Training Accuracy: 0.638095238095238\n",
            "Validation Accuracy: 0.7333333333333333 \n",
            "\n",
            "Epoch 40\n",
            "Training Accuracy: 0.8\n",
            "Validation Accuracy: 0.8888888888888888 \n",
            "\n",
            "Epoch 50\n",
            "Training Accuracy: 0.7428571428571429\n",
            "Validation Accuracy: 0.8 \n",
            "\n",
            "Epoch 60\n",
            "Training Accuracy: 0.8095238095238095\n",
            "Validation Accuracy: 0.8888888888888888 \n",
            "\n",
            "Epoch 70\n",
            "Training Accuracy: 0.8476190476190476\n",
            "Validation Accuracy: 0.9555555555555556 \n",
            "\n",
            "Epoch 80\n",
            "Training Accuracy: 0.638095238095238\n",
            "Validation Accuracy: 0.7333333333333333 \n",
            "\n",
            "Epoch 90\n",
            "Training Accuracy: 0.6476190476190476\n",
            "Validation Accuracy: 0.7555555555555555 \n",
            "\n",
            "Epoch 100\n",
            "Training Accuracy: 0.6761904761904762\n",
            "Validation Accuracy: 0.7777777777777778 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hasil Percobaan dengan Variasi Learning Rate"
      ],
      "metadata": {
        "id": "0xcHRPloUL_7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the results of training in dataframe\n",
        "results_df = pd.DataFrame(results, columns=['Learning Rate', 'Training Accuracy', 'Testing Accuracy'])\n",
        "print(results_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Um-hB8JxTaW-",
        "outputId": "ff293b08-94df-4cd1-c8b8-fa008310220b"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Learning Rate  Training Accuracy  Testing Accuracy\n",
            "0           0.10           0.847619          0.933333\n",
            "1           0.25           0.647619          0.755556\n",
            "2           0.50           0.676190          0.777778\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dari hasil percobaan, didapatkan bahwa dengan dataset yang ada :\n",
        "\n",
        "- nilai learning rate yang lebih kecil memiliki tingkat akurasi yang lebih tinggi dibandingkan nilai learning rate yang lebih besar\n",
        "- hasil model mengindikasi terjadinya underfitting dikarenakan nilai dari training accuracy lebih rendah dibandingkan test accuracy dengan perbedaan accuracy yang cukup besar sebanyak 9-11 %"
      ],
      "metadata": {
        "id": "8vovDPqjmtWP"
      }
    }
  ]
}